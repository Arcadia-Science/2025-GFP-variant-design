{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "generation-header",
   "metadata": {},
   "source": [
    "# Sequence Generation and Activity Prediction\n",
    "\n",
    "This notebook loads the trained CNN ensemble model, generates new protein sequences, and predicts their activities."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "setup-header",
   "metadata": {},
   "source": [
    "# Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "pip-install",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/site-packages (4.67.1)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.11/site-packages (2.3.2)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.11/site-packages (2.3.2)\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.11/site-packages (2.8.0)\n",
      "Collecting fair-esm\n",
      "  Downloading fair_esm-2.0.0-py3-none-any.whl.metadata (37 kB)\n",
      "Collecting fairscale\n",
      "  Downloading fairscale-0.4.13.tar.gz (266 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Installing backend dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/site-packages (from torch) (3.19.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.11/site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/site-packages (from torch) (3.5)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/site-packages (from torch) (2025.7.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in /usr/local/lib/python3.11/site-packages (from torch) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in /usr/local/lib/python3.11/site-packages (from torch) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in /usr/local/lib/python3.11/site-packages (from torch) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.11/site-packages (from torch) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in /usr/local/lib/python3.11/site-packages (from torch) (12.8.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in /usr/local/lib/python3.11/site-packages (from torch) (11.3.3.83)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in /usr/local/lib/python3.11/site-packages (from torch) (10.3.9.90)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in /usr/local/lib/python3.11/site-packages (from torch) (11.7.3.90)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in /usr/local/lib/python3.11/site-packages (from torch) (12.5.8.93)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.11/site-packages (from torch) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.11/site-packages (from torch) (2.27.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in /usr/local/lib/python3.11/site-packages (from torch) (12.8.90)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in /usr/local/lib/python3.11/site-packages (from torch) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in /usr/local/lib/python3.11/site-packages (from torch) (1.13.1.3)\n",
      "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.11/site-packages (from torch) (3.4.0)\n",
      "Requirement already satisfied: setuptools>=40.8.0 in /usr/local/lib/python3.11/site-packages (from triton==3.4.0->torch) (68.1.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/site-packages (from jinja2->torch) (3.0.2)\n",
      "Downloading fair_esm-2.0.0-py3-none-any.whl (93 kB)\n",
      "Building wheels for collected packages: fairscale\n",
      "  Building wheel for fairscale (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for fairscale: filename=fairscale-0.4.13-py3-none-any.whl size=332208 sha256=32e44e3858ec7eefa622f72e0cd725371c3edb12600b1f8d44cde39404e85ec2\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-541g2cuj/wheels/95/ef/96/5044bde220b2ea299bdc6ec05051e0ef187fad45b341d1c273\n",
      "Successfully built fairscale\n",
      "Installing collected packages: fair-esm, fairscale\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2/2\u001b[0m [fairscale]/2\u001b[0m [fairscale]\n",
      "\u001b[1A\u001b[2KSuccessfully installed fair-esm-2.0.0 fairscale-0.4.13\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.1.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! pip install tqdm numpy pandas torch fair-esm fairscale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from typing import List, Set\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "import src.models as models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wpqo73e6f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define data paths\n",
    "EXISTING_SEQUENCES_PATH = \"data/seq_and_score.csv\"\n",
    "OUTPUTS_DIR = Path(\"outputs\")\n",
    "MODEL_PATH = OUTPUTS_DIR / \"cnn_ensemble_model.pth\"\n",
    "METRICS_PATH = OUTPUTS_DIR / \"training_metrics.json\"\n",
    "FASTA_PATH = OUTPUTS_DIR / \"new_seqs.fasta\"\n",
    "EMBEDDINGS_DIR = OUTPUTS_DIR / \"new_seq_embeddings\"\n",
    "RESULTS_CSV_PATH = OUTPUTS_DIR / \"all_sequences_predictions.csv\"\n",
    "RESULTS_PT_PATH = OUTPUTS_DIR / \"all_sequences_predictions.pt\"\n",
    "TOP_5_FASTA_PATH = OUTPUTS_DIR / \"top_5_sequences.fasta\"\n",
    "BOTTOM_5_FASTA_PATH = OUTPUTS_DIR / \"bottom_5_sequences.fasta\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "model-loading-header",
   "metadata": {},
   "source": [
    "# Load Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "load-model",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded trained model from mount/outputs/cnn_ensemble_model.pth on cuda\n"
     ]
    }
   ],
   "source": [
    "# Load the trained model\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "model = models.Ensemble().to(device)\n",
    "\n",
    "if not MODEL_PATH.exists():\n",
    "    raise FileNotFoundError(f\"Trained model not found at {MODEL_PATH}. Please run 01_train_model.ipynb first.\")\n",
    "\n",
    "model.load_state_dict(torch.load(MODEL_PATH, map_location=device))\n",
    "model.eval()\n",
    "print(f\"Loaded trained model from {MODEL_PATH} on {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "load-metrics",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model training metrics:\n",
      "  Final R²: 0.8505\n",
      "  Epochs trained: 200\n"
     ]
    }
   ],
   "source": [
    "# Load and display training metrics\n",
    "import json\n",
    "if METRICS_PATH.exists():\n",
    "    with open(METRICS_PATH, 'r') as f:\n",
    "        metrics = json.load(f)\n",
    "    print(f\"Model training metrics:\")\n",
    "    print(f\"  Final R²: {metrics['final_r2']:.4f}\")\n",
    "    print(f\"  Epochs trained: {metrics['epochs_trained']}\")\n",
    "else:\n",
    "    print(f\"Training metrics not found at {METRICS_PATH}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sequence-generation-header",
   "metadata": {},
   "source": [
    "# Sequence Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "wildtype-sequence",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wild-type sequence length: 238\n"
     ]
    }
   ],
   "source": [
    "# Wild-type GFP sequence\n",
    "wt_seq = \"MSKGEELFTGVVPILVELDGDVNGHKFSVSGEGEGDATYGKLTLKFICTTGKLPVPWPTLVTTLSYGVQCFSRYPDHMKQHDFFKSAMPEGYVQERTIFFKDDGNYKTRAEVKFEGDTLVNRIELKGIDFKEDGNILGHKLEYNYNSHNVYIMADKQKNGIKVNFKIRHNIEDGSVQLADHYQQNTPIGDGPVLLPDNHYLSTQSALSKDPNEKRDHMVLLEFVTAAGITHGMDELYK\"\n",
    "print(f\"Wild-type sequence length: {len(wt_seq)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "sequence-generator",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_mutant_sequences(wt_sequence: str, n_mutations: int = 4, n_sequences: int = 10) -> List[str]:\n",
    "    \"\"\"\n",
    "    Generate protein sequences with exactly n mutations from a wild-type sequence.\n",
    "    \n",
    "    Args:\n",
    "        wt_sequence (str): Wild-type protein sequence using single letter amino acid codes\n",
    "        n_mutations (int): Number of mutations per sequence\n",
    "        n_sequences (int): Number of mutant sequences to generate\n",
    "    \n",
    "    Returns:\n",
    "        List[str]: List of mutated sequences\n",
    "    \n",
    "    Raises:\n",
    "        ValueError: If inputs are invalid\n",
    "    \"\"\"\n",
    "    VALID_AA = set('ACDEFGHIKLMNPQRSTVWY')\n",
    "\n",
    "    def mutate_sequence(seq: str, positions: List[int]) -> str:\n",
    "        seq_list = list(seq)\n",
    "        key = []\n",
    "        for pos in positions:\n",
    "            \n",
    "            # Get all possible mutations at this position\n",
    "            possible_mutations = VALID_AA - {seq[pos]}\n",
    "\n",
    "            mutation = random.choice(list(possible_mutations))\n",
    "            seq_list[pos] = mutation\n",
    "            key.append(f\"{pos}{mutation}\")\n",
    "        return \":\".join(key), ''.join(seq_list)\n",
    "    \n",
    "    generated_sequences: Set[str] = set()\n",
    "    \n",
    "    while len(generated_sequences) < n_sequences:\n",
    "        mutation_positions = random.sample(range(len(wt_sequence)), n_mutations)\n",
    "        key, new_sequence = mutate_sequence(wt_sequence, mutation_positions)\n",
    "        \n",
    "        if new_sequence not in generated_sequences:\n",
    "            generated_sequences.add((key, new_sequence))\n",
    "            \n",
    "    return list(generated_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "generate-mutants",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating mutant sequences...\n",
      "Generated 1000 mutant sequences\n"
     ]
    }
   ],
   "source": [
    "# Generate mutant sequences\n",
    "print(\"Generating mutant sequences...\")\n",
    "mutants = generate_mutant_sequences(wt_seq, n_mutations=4, n_sequences=1000)\n",
    "print(f\"Generated {len(mutants)} mutant sequences\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "filtering-header",
   "metadata": {},
   "source": [
    "# Filter Out Existing Sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "filter-sequences",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 51715 existing sequences to filter out from mount/data/seq_and_score.csv\n",
      "After filtering: 1000 new sequences to evaluate\n"
     ]
    }
   ],
   "source": [
    "# Load existing sequences to filter out duplicates\n",
    "df_seqs = pd.read_csv(EXISTING_SEQUENCES_PATH)\n",
    "existing_seqs = set(df_seqs.sequence)\n",
    "print(f\"Found {len(existing_seqs)} existing sequences to filter out from {EXISTING_SEQUENCES_PATH}\")\n",
    "\n",
    "# Filter to only new sequences\n",
    "new_seqs = [(k, s) for k, s in mutants if s not in existing_seqs]\n",
    "print(f\"After filtering: {len(new_seqs)} new sequences to evaluate\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "save-fasta",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 1000 sequences to mount/outputs/new_seqs.fasta\n"
     ]
    }
   ],
   "source": [
    "# Create outputs directory and save sequences to FASTA\n",
    "OUTPUTS_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "with open(FASTA_PATH, \"w\") as fh:\n",
    "    for key, seq in new_seqs:\n",
    "        fh.write(f\">{key}\\n\")\n",
    "        fh.write(f\"{seq}\\n\")\n",
    "        \n",
    "print(f\"Saved {len(new_seqs)} sequences to {FASTA_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "embedding-header",
   "metadata": {},
   "source": [
    "# Generate Embeddings for New Sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2bd78b52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Get:1 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
      "Get:2 http://archive.ubuntu.com/ubuntu jammy InRelease [270 kB]                \u001b[0m\u001b[33m\n",
      "Get:3 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
      "Get:4 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]\n",
      "Get:5 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [3253 kB]\n",
      "Get:6 http://security.ubuntu.com/ubuntu jammy-security/multiverse amd64 Packages [48.5 kB]\n",
      "Get:7 http://security.ubuntu.com/ubuntu jammy-security/restricted amd64 Packages [5235 kB]\n",
      "Get:8 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1271 kB]\n",
      "Get:9 http://archive.ubuntu.com/ubuntu jammy/universe amd64 Packages [17.5 MB]33m\u001b[33m\n",
      "Get:10 http://archive.ubuntu.com/ubuntu jammy/multiverse amd64 Packages [266 kB]\n",
      "Get:11 http://archive.ubuntu.com/ubuntu jammy/main amd64 Packages [1792 kB]\n",
      "Get:12 http://archive.ubuntu.com/ubuntu jammy/restricted amd64 Packages [164 kB]\n",
      "Get:13 http://archive.ubuntu.com/ubuntu jammy-updates/restricted amd64 Packages [5430 kB]\n",
      "Get:14 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1575 kB]\n",
      "Get:15 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [3569 kB]\n",
      "Get:16 http://archive.ubuntu.com/ubuntu jammy-updates/multiverse amd64 Packages [75.9 kB]\n",
      "Get:17 http://archive.ubuntu.com/ubuntu jammy-backports/universe amd64 Packages [35.2 kB]\n",
      "Get:18 http://archive.ubuntu.com/ubuntu jammy-backports/main amd64 Packages [83.2 kB]\n",
      "Fetched 40.9 MB in 4s (11.4 MB/s)33m                       \u001b[0m\u001b[33m\u001b[33m\u001b[33m\u001b[33m\u001b[33m\u001b[33m\u001b[33m\n",
      "Reading package lists... Done\n",
      "Building dependency tree... Done\n",
      "Reading state information... Done\n",
      "20 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
      "Reading package lists... Done\n",
      "Building dependency tree... Done\n",
      "Reading state information... Done\n",
      "The following additional packages will be installed:\n",
      "  openssl\n",
      "The following NEW packages will be installed:\n",
      "  ca-certificates openssl\n",
      "0 upgraded, 2 newly installed, 0 to remove and 20 not upgraded.\n",
      "Need to get 1348 kB of archives.\n",
      "After this operation, 2511 kB of additional disk space will be used.\n",
      "Get:1 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 openssl amd64 3.0.2-0ubuntu1.19 [1186 kB]\n",
      "Get:2 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 ca-certificates all 20240203~22.04.1 [162 kB]\n",
      "Fetched 1348 kB in 0s (7358 kB/s)         \u001b[0m\u001b[33m\n",
      "debconf: delaying package configuration, since apt-utils is not installed\n",
      "\n",
      "\u001b7\u001b[0;23r\u001b8\u001b[1ASelecting previously unselected package openssl.\n",
      "(Reading database ... 4393 files and directories currently installed.)\n",
      "Preparing to unpack .../openssl_3.0.2-0ubuntu1.19_amd64.deb ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [  0%]\u001b[49m\u001b[39m [..........................................................] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 11%]\u001b[49m\u001b[39m [######....................................................] \u001b8Unpacking openssl (3.0.2-0ubuntu1.19) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 22%]\u001b[49m\u001b[39m [############..............................................] \u001b8Selecting previously unselected package ca-certificates.\n",
      "Preparing to unpack .../ca-certificates_20240203~22.04.1_all.deb ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 33%]\u001b[49m\u001b[39m [###################.......................................] \u001b8Unpacking ca-certificates (20240203~22.04.1) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 44%]\u001b[49m\u001b[39m [#########################.................................] \u001b8Setting up openssl (3.0.2-0ubuntu1.19) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 56%]\u001b[49m\u001b[39m [################################..........................] \u001b8\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 67%]\u001b[49m\u001b[39m [######################################....................] \u001b8Setting up ca-certificates (20240203~22.04.1) ...\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 78%]\u001b[49m\u001b[39m [#############################################.............] \u001b8debconf: unable to initialize frontend: Dialog\n",
      "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78.)\n",
      "debconf: falling back to frontend: Readline\n",
      "debconf: unable to initialize frontend: Readline\n",
      "debconf: (Can't locate Term/ReadLine.pm in @INC (you may need to install the Term::ReadLine module) (@INC contains: /etc/perl /usr/local/lib/x86_64-linux-gnu/perl/5.34.0 /usr/local/share/perl/5.34.0 /usr/lib/x86_64-linux-gnu/perl5/5.34 /usr/share/perl5 /usr/lib/x86_64-linux-gnu/perl-base /usr/lib/x86_64-linux-gnu/perl/5.34 /usr/share/perl/5.34 /usr/local/lib/site_perl) at /usr/share/perl5/Debconf/FrontEnd/Readline.pm line 7.)\n",
      "debconf: falling back to frontend: Teletype\n",
      "Updating certificates in /etc/ssl/certs...\n",
      "146 added, 0 removed; done.\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 89%]\u001b[49m\u001b[39m [###################################################.......] \u001b8Processing triggers for ca-certificates (20240203~22.04.1) ...\n",
      "Updating certificates in /etc/ssl/certs...\n",
      "0 added, 0 removed; done.\n",
      "Running hooks in /etc/ca-certificates/update.d...\n",
      "done.\n",
      "\u001b7\u001b[24;0f\u001b[42m\u001b[30mProgress: [ 91%]\u001b[49m\u001b[39m [####################################################......] \u001b8\n",
      "\u001b7\u001b[0;24r\u001b8\u001b[1A\u001b[JUpdating certificates in /etc/ssl/certs...\n",
      "0 added, 0 removed; done.\n",
      "Running hooks in /etc/ca-certificates/update.d...\n",
      "done.\n"
     ]
    }
   ],
   "source": [
    "! apt update && apt install -y ca-certificates && update-ca-certificates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "generate-embeddings",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating embeddings for 1000 sequences...\n",
      "This may take several minutes depending on the number of sequences.\n",
      "Downloading: \"https://dl.fbaipublicfiles.com/fair-esm/models/esm2_t48_15B_UR50D.pt\" to /root/.cache/torch/hub/checkpoints/esm2_t48_15B_UR50D.pt\n",
      "Downloading: \"https://dl.fbaipublicfiles.com/fair-esm/regression/esm2_t48_15B_UR50D-contact-regression.pt\" to /root/.cache/torch/hub/checkpoints/esm2_t48_15B_UR50D-contact-regression.pt\n",
      "Processing 1 of 500 batches (2 sequences)\n",
      "/usr/local/lib/python3.11/site-packages/fairscale/nn/data_parallel/fully_sharded_data_parallel.py:2562: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  if data.storage().size() > 0:\n",
      "Processing 2 of 500 batches (2 sequences)\n",
      "Processing 3 of 500 batches (2 sequences)\n",
      "Processing 4 of 500 batches (2 sequences)\n",
      "Processing 5 of 500 batches (2 sequences)\n",
      "Processing 6 of 500 batches (2 sequences)\n",
      "Processing 7 of 500 batches (2 sequences)\n",
      "Processing 8 of 500 batches (2 sequences)\n",
      "Processing 9 of 500 batches (2 sequences)\n",
      "Processing 10 of 500 batches (2 sequences)\n",
      "Processing 11 of 500 batches (2 sequences)\n",
      "Processing 12 of 500 batches (2 sequences)\n",
      "Processing 13 of 500 batches (2 sequences)\n",
      "Processing 14 of 500 batches (2 sequences)\n",
      "Processing 15 of 500 batches (2 sequences)\n",
      "Processing 16 of 500 batches (2 sequences)\n",
      "Processing 17 of 500 batches (2 sequences)\n",
      "Processing 18 of 500 batches (2 sequences)\n",
      "Processing 19 of 500 batches (2 sequences)\n",
      "Processing 20 of 500 batches (2 sequences)\n",
      "Processing 21 of 500 batches (2 sequences)\n",
      "Processing 22 of 500 batches (2 sequences)\n",
      "Processing 23 of 500 batches (2 sequences)\n",
      "Processing 24 of 500 batches (2 sequences)\n",
      "Processing 25 of 500 batches (2 sequences)\n",
      "Processing 26 of 500 batches (2 sequences)\n",
      "Processing 27 of 500 batches (2 sequences)\n",
      "Processing 28 of 500 batches (2 sequences)\n",
      "Processing 29 of 500 batches (2 sequences)\n",
      "Processing 30 of 500 batches (2 sequences)\n",
      "Processing 31 of 500 batches (2 sequences)\n",
      "Processing 32 of 500 batches (2 sequences)\n",
      "Processing 33 of 500 batches (2 sequences)\n",
      "Processing 34 of 500 batches (2 sequences)\n",
      "Processing 35 of 500 batches (2 sequences)\n",
      "Processing 36 of 500 batches (2 sequences)\n",
      "Processing 37 of 500 batches (2 sequences)\n",
      "Processing 38 of 500 batches (2 sequences)\n",
      "Processing 39 of 500 batches (2 sequences)\n",
      "Processing 40 of 500 batches (2 sequences)\n",
      "Processing 41 of 500 batches (2 sequences)\n",
      "Processing 42 of 500 batches (2 sequences)\n",
      "Processing 43 of 500 batches (2 sequences)\n",
      "Processing 44 of 500 batches (2 sequences)\n",
      "Processing 45 of 500 batches (2 sequences)\n",
      "Processing 46 of 500 batches (2 sequences)\n",
      "Processing 47 of 500 batches (2 sequences)\n",
      "Processing 48 of 500 batches (2 sequences)\n",
      "Processing 49 of 500 batches (2 sequences)\n",
      "Processing 50 of 500 batches (2 sequences)\n",
      "Processing 51 of 500 batches (2 sequences)\n",
      "Processing 52 of 500 batches (2 sequences)\n",
      "Processing 53 of 500 batches (2 sequences)\n",
      "Processing 54 of 500 batches (2 sequences)\n",
      "Processing 55 of 500 batches (2 sequences)\n",
      "Processing 56 of 500 batches (2 sequences)\n",
      "Processing 57 of 500 batches (2 sequences)\n",
      "Processing 58 of 500 batches (2 sequences)\n",
      "Processing 59 of 500 batches (2 sequences)\n",
      "Processing 60 of 500 batches (2 sequences)\n",
      "Processing 61 of 500 batches (2 sequences)\n",
      "Processing 62 of 500 batches (2 sequences)\n",
      "Processing 63 of 500 batches (2 sequences)\n",
      "Processing 64 of 500 batches (2 sequences)\n",
      "Processing 65 of 500 batches (2 sequences)\n",
      "Processing 66 of 500 batches (2 sequences)\n",
      "Processing 67 of 500 batches (2 sequences)\n",
      "Processing 68 of 500 batches (2 sequences)\n",
      "Processing 69 of 500 batches (2 sequences)\n",
      "Processing 70 of 500 batches (2 sequences)\n",
      "Processing 71 of 500 batches (2 sequences)\n",
      "Processing 72 of 500 batches (2 sequences)\n",
      "Processing 73 of 500 batches (2 sequences)\n",
      "Processing 74 of 500 batches (2 sequences)\n",
      "Processing 75 of 500 batches (2 sequences)\n",
      "Processing 76 of 500 batches (2 sequences)\n",
      "Processing 77 of 500 batches (2 sequences)\n",
      "Processing 78 of 500 batches (2 sequences)\n",
      "Processing 79 of 500 batches (2 sequences)\n",
      "Processing 80 of 500 batches (2 sequences)\n",
      "Processing 81 of 500 batches (2 sequences)\n",
      "Processing 82 of 500 batches (2 sequences)\n",
      "Processing 83 of 500 batches (2 sequences)\n",
      "Processing 84 of 500 batches (2 sequences)\n",
      "Processing 85 of 500 batches (2 sequences)\n",
      "Processing 86 of 500 batches (2 sequences)\n",
      "Processing 87 of 500 batches (2 sequences)\n",
      "Processing 88 of 500 batches (2 sequences)\n",
      "Processing 89 of 500 batches (2 sequences)\n",
      "Processing 90 of 500 batches (2 sequences)\n",
      "Processing 91 of 500 batches (2 sequences)\n",
      "Processing 92 of 500 batches (2 sequences)\n",
      "Processing 93 of 500 batches (2 sequences)\n",
      "Processing 94 of 500 batches (2 sequences)\n",
      "Processing 95 of 500 batches (2 sequences)\n",
      "Processing 96 of 500 batches (2 sequences)\n",
      "Processing 97 of 500 batches (2 sequences)\n",
      "Processing 98 of 500 batches (2 sequences)\n",
      "Processing 99 of 500 batches (2 sequences)\n",
      "Processing 100 of 500 batches (2 sequences)\n",
      "Processing 101 of 500 batches (2 sequences)\n",
      "Processing 102 of 500 batches (2 sequences)\n",
      "Processing 103 of 500 batches (2 sequences)\n",
      "Processing 104 of 500 batches (2 sequences)\n",
      "Processing 105 of 500 batches (2 sequences)\n",
      "Processing 106 of 500 batches (2 sequences)\n",
      "Processing 107 of 500 batches (2 sequences)\n",
      "Processing 108 of 500 batches (2 sequences)\n",
      "Processing 109 of 500 batches (2 sequences)\n",
      "Processing 110 of 500 batches (2 sequences)\n",
      "Processing 111 of 500 batches (2 sequences)\n",
      "Processing 112 of 500 batches (2 sequences)\n",
      "Processing 113 of 500 batches (2 sequences)\n",
      "Processing 114 of 500 batches (2 sequences)\n",
      "Processing 115 of 500 batches (2 sequences)\n",
      "Processing 116 of 500 batches (2 sequences)\n",
      "Processing 117 of 500 batches (2 sequences)\n",
      "Processing 118 of 500 batches (2 sequences)\n",
      "Processing 119 of 500 batches (2 sequences)\n",
      "Processing 120 of 500 batches (2 sequences)\n",
      "Processing 121 of 500 batches (2 sequences)\n",
      "Processing 122 of 500 batches (2 sequences)\n",
      "Processing 123 of 500 batches (2 sequences)\n",
      "Processing 124 of 500 batches (2 sequences)\n",
      "Processing 125 of 500 batches (2 sequences)\n",
      "Processing 126 of 500 batches (2 sequences)\n",
      "Processing 127 of 500 batches (2 sequences)\n",
      "Processing 128 of 500 batches (2 sequences)\n",
      "Processing 129 of 500 batches (2 sequences)\n",
      "Processing 130 of 500 batches (2 sequences)\n",
      "Processing 131 of 500 batches (2 sequences)\n",
      "Processing 132 of 500 batches (2 sequences)\n",
      "Processing 133 of 500 batches (2 sequences)\n",
      "Processing 134 of 500 batches (2 sequences)\n",
      "Processing 135 of 500 batches (2 sequences)\n",
      "Processing 136 of 500 batches (2 sequences)\n",
      "Processing 137 of 500 batches (2 sequences)\n",
      "Processing 138 of 500 batches (2 sequences)\n",
      "Processing 139 of 500 batches (2 sequences)\n",
      "Processing 140 of 500 batches (2 sequences)\n",
      "Processing 141 of 500 batches (2 sequences)\n",
      "Processing 142 of 500 batches (2 sequences)\n",
      "Processing 143 of 500 batches (2 sequences)\n",
      "Processing 144 of 500 batches (2 sequences)\n",
      "Processing 145 of 500 batches (2 sequences)\n",
      "Processing 146 of 500 batches (2 sequences)\n",
      "Processing 147 of 500 batches (2 sequences)\n",
      "Processing 148 of 500 batches (2 sequences)\n",
      "Processing 149 of 500 batches (2 sequences)\n",
      "Processing 150 of 500 batches (2 sequences)\n",
      "Processing 151 of 500 batches (2 sequences)\n",
      "Processing 152 of 500 batches (2 sequences)\n",
      "Processing 153 of 500 batches (2 sequences)\n",
      "Processing 154 of 500 batches (2 sequences)\n",
      "Processing 155 of 500 batches (2 sequences)\n",
      "Processing 156 of 500 batches (2 sequences)\n",
      "Processing 157 of 500 batches (2 sequences)\n",
      "Processing 158 of 500 batches (2 sequences)\n",
      "Processing 159 of 500 batches (2 sequences)\n",
      "Processing 160 of 500 batches (2 sequences)\n",
      "Processing 161 of 500 batches (2 sequences)\n",
      "Processing 162 of 500 batches (2 sequences)\n",
      "Processing 163 of 500 batches (2 sequences)\n",
      "Processing 164 of 500 batches (2 sequences)\n",
      "Processing 165 of 500 batches (2 sequences)\n",
      "Processing 166 of 500 batches (2 sequences)\n",
      "Processing 167 of 500 batches (2 sequences)\n",
      "Processing 168 of 500 batches (2 sequences)\n",
      "Processing 169 of 500 batches (2 sequences)\n",
      "Processing 170 of 500 batches (2 sequences)\n",
      "Processing 171 of 500 batches (2 sequences)\n",
      "Processing 172 of 500 batches (2 sequences)\n",
      "Processing 173 of 500 batches (2 sequences)\n",
      "Processing 174 of 500 batches (2 sequences)\n",
      "Processing 175 of 500 batches (2 sequences)\n",
      "Processing 176 of 500 batches (2 sequences)\n",
      "Processing 177 of 500 batches (2 sequences)\n",
      "Processing 178 of 500 batches (2 sequences)\n",
      "Processing 179 of 500 batches (2 sequences)\n",
      "Processing 180 of 500 batches (2 sequences)\n",
      "Processing 181 of 500 batches (2 sequences)\n",
      "Processing 182 of 500 batches (2 sequences)\n",
      "Processing 183 of 500 batches (2 sequences)\n",
      "Processing 184 of 500 batches (2 sequences)\n",
      "Processing 185 of 500 batches (2 sequences)\n",
      "Processing 186 of 500 batches (2 sequences)\n",
      "Processing 187 of 500 batches (2 sequences)\n",
      "Processing 188 of 500 batches (2 sequences)\n",
      "Processing 189 of 500 batches (2 sequences)\n",
      "Processing 190 of 500 batches (2 sequences)\n",
      "Processing 191 of 500 batches (2 sequences)\n",
      "Processing 192 of 500 batches (2 sequences)\n",
      "Processing 193 of 500 batches (2 sequences)\n",
      "Processing 194 of 500 batches (2 sequences)\n",
      "Processing 195 of 500 batches (2 sequences)\n",
      "Processing 196 of 500 batches (2 sequences)\n",
      "Processing 197 of 500 batches (2 sequences)\n",
      "Processing 198 of 500 batches (2 sequences)\n",
      "Processing 199 of 500 batches (2 sequences)\n",
      "Processing 200 of 500 batches (2 sequences)\n",
      "Processing 201 of 500 batches (2 sequences)\n",
      "Processing 202 of 500 batches (2 sequences)\n",
      "Processing 203 of 500 batches (2 sequences)\n",
      "Processing 204 of 500 batches (2 sequences)\n",
      "Processing 205 of 500 batches (2 sequences)\n",
      "Processing 206 of 500 batches (2 sequences)\n",
      "Processing 207 of 500 batches (2 sequences)\n",
      "Processing 208 of 500 batches (2 sequences)\n",
      "Processing 209 of 500 batches (2 sequences)\n",
      "Processing 210 of 500 batches (2 sequences)\n",
      "Processing 211 of 500 batches (2 sequences)\n",
      "Processing 212 of 500 batches (2 sequences)\n",
      "Processing 213 of 500 batches (2 sequences)\n",
      "Processing 214 of 500 batches (2 sequences)\n",
      "Processing 215 of 500 batches (2 sequences)\n",
      "Processing 216 of 500 batches (2 sequences)\n",
      "Processing 217 of 500 batches (2 sequences)\n",
      "Processing 218 of 500 batches (2 sequences)\n",
      "Processing 219 of 500 batches (2 sequences)\n",
      "Processing 220 of 500 batches (2 sequences)\n",
      "Processing 221 of 500 batches (2 sequences)\n",
      "Processing 222 of 500 batches (2 sequences)\n",
      "Processing 223 of 500 batches (2 sequences)\n",
      "Processing 224 of 500 batches (2 sequences)\n",
      "Processing 225 of 500 batches (2 sequences)\n",
      "Processing 226 of 500 batches (2 sequences)\n",
      "Processing 227 of 500 batches (2 sequences)\n",
      "Processing 228 of 500 batches (2 sequences)\n",
      "Processing 229 of 500 batches (2 sequences)\n",
      "Processing 230 of 500 batches (2 sequences)\n",
      "Processing 231 of 500 batches (2 sequences)\n",
      "Processing 232 of 500 batches (2 sequences)\n",
      "Processing 233 of 500 batches (2 sequences)\n",
      "Processing 234 of 500 batches (2 sequences)\n",
      "Processing 235 of 500 batches (2 sequences)\n",
      "Processing 236 of 500 batches (2 sequences)\n",
      "Processing 237 of 500 batches (2 sequences)\n",
      "Processing 238 of 500 batches (2 sequences)\n",
      "Processing 239 of 500 batches (2 sequences)\n",
      "Processing 240 of 500 batches (2 sequences)\n",
      "Processing 241 of 500 batches (2 sequences)\n",
      "Processing 242 of 500 batches (2 sequences)\n",
      "Processing 243 of 500 batches (2 sequences)\n",
      "Processing 244 of 500 batches (2 sequences)\n",
      "Processing 245 of 500 batches (2 sequences)\n",
      "Processing 246 of 500 batches (2 sequences)\n",
      "Processing 247 of 500 batches (2 sequences)\n",
      "Processing 248 of 500 batches (2 sequences)\n",
      "Processing 249 of 500 batches (2 sequences)\n",
      "Processing 250 of 500 batches (2 sequences)\n",
      "Processing 251 of 500 batches (2 sequences)\n",
      "Processing 252 of 500 batches (2 sequences)\n",
      "Processing 253 of 500 batches (2 sequences)\n",
      "Processing 254 of 500 batches (2 sequences)\n",
      "Processing 255 of 500 batches (2 sequences)\n",
      "Processing 256 of 500 batches (2 sequences)\n",
      "Processing 257 of 500 batches (2 sequences)\n",
      "Processing 258 of 500 batches (2 sequences)\n",
      "Processing 259 of 500 batches (2 sequences)\n",
      "Processing 260 of 500 batches (2 sequences)\n",
      "Processing 261 of 500 batches (2 sequences)\n",
      "Processing 262 of 500 batches (2 sequences)\n",
      "Processing 263 of 500 batches (2 sequences)\n",
      "Processing 264 of 500 batches (2 sequences)\n",
      "Processing 265 of 500 batches (2 sequences)\n",
      "Processing 266 of 500 batches (2 sequences)\n",
      "Processing 267 of 500 batches (2 sequences)\n",
      "Processing 268 of 500 batches (2 sequences)\n",
      "Processing 269 of 500 batches (2 sequences)\n",
      "Processing 270 of 500 batches (2 sequences)\n",
      "Processing 271 of 500 batches (2 sequences)\n",
      "Processing 272 of 500 batches (2 sequences)\n",
      "Processing 273 of 500 batches (2 sequences)\n",
      "Processing 274 of 500 batches (2 sequences)\n",
      "Processing 275 of 500 batches (2 sequences)\n",
      "Processing 276 of 500 batches (2 sequences)\n",
      "Processing 277 of 500 batches (2 sequences)\n",
      "Processing 278 of 500 batches (2 sequences)\n",
      "Processing 279 of 500 batches (2 sequences)\n",
      "Processing 280 of 500 batches (2 sequences)\n",
      "Processing 281 of 500 batches (2 sequences)\n",
      "Processing 282 of 500 batches (2 sequences)\n",
      "Processing 283 of 500 batches (2 sequences)\n",
      "Processing 284 of 500 batches (2 sequences)\n",
      "Processing 285 of 500 batches (2 sequences)\n",
      "Processing 286 of 500 batches (2 sequences)\n",
      "Processing 287 of 500 batches (2 sequences)\n",
      "Processing 288 of 500 batches (2 sequences)\n",
      "Processing 289 of 500 batches (2 sequences)\n",
      "Processing 290 of 500 batches (2 sequences)\n",
      "Processing 291 of 500 batches (2 sequences)\n",
      "Processing 292 of 500 batches (2 sequences)\n",
      "Processing 293 of 500 batches (2 sequences)\n",
      "Processing 294 of 500 batches (2 sequences)\n",
      "Processing 295 of 500 batches (2 sequences)\n",
      "Processing 296 of 500 batches (2 sequences)\n",
      "Processing 297 of 500 batches (2 sequences)\n",
      "Processing 298 of 500 batches (2 sequences)\n",
      "Processing 299 of 500 batches (2 sequences)\n",
      "Processing 300 of 500 batches (2 sequences)\n",
      "Processing 301 of 500 batches (2 sequences)\n",
      "Processing 302 of 500 batches (2 sequences)\n",
      "Processing 303 of 500 batches (2 sequences)\n",
      "Processing 304 of 500 batches (2 sequences)\n",
      "Processing 305 of 500 batches (2 sequences)\n",
      "Processing 306 of 500 batches (2 sequences)\n",
      "Processing 307 of 500 batches (2 sequences)\n",
      "Processing 308 of 500 batches (2 sequences)\n",
      "Processing 309 of 500 batches (2 sequences)\n",
      "Processing 310 of 500 batches (2 sequences)\n",
      "Processing 311 of 500 batches (2 sequences)\n",
      "Processing 312 of 500 batches (2 sequences)\n",
      "Processing 313 of 500 batches (2 sequences)\n",
      "Processing 314 of 500 batches (2 sequences)\n",
      "Processing 315 of 500 batches (2 sequences)\n",
      "Processing 316 of 500 batches (2 sequences)\n",
      "Processing 317 of 500 batches (2 sequences)\n",
      "Processing 318 of 500 batches (2 sequences)\n",
      "Processing 319 of 500 batches (2 sequences)\n",
      "Processing 320 of 500 batches (2 sequences)\n",
      "Processing 321 of 500 batches (2 sequences)\n",
      "Processing 322 of 500 batches (2 sequences)\n",
      "Processing 323 of 500 batches (2 sequences)\n",
      "Processing 324 of 500 batches (2 sequences)\n",
      "Processing 325 of 500 batches (2 sequences)\n",
      "Processing 326 of 500 batches (2 sequences)\n",
      "Processing 327 of 500 batches (2 sequences)\n",
      "Processing 328 of 500 batches (2 sequences)\n",
      "Processing 329 of 500 batches (2 sequences)\n",
      "Processing 330 of 500 batches (2 sequences)\n",
      "Processing 331 of 500 batches (2 sequences)\n",
      "Processing 332 of 500 batches (2 sequences)\n",
      "Processing 333 of 500 batches (2 sequences)\n",
      "Processing 334 of 500 batches (2 sequences)\n",
      "Processing 335 of 500 batches (2 sequences)\n",
      "Processing 336 of 500 batches (2 sequences)\n",
      "Processing 337 of 500 batches (2 sequences)\n",
      "Processing 338 of 500 batches (2 sequences)\n",
      "Processing 339 of 500 batches (2 sequences)\n",
      "Processing 340 of 500 batches (2 sequences)\n",
      "Processing 341 of 500 batches (2 sequences)\n",
      "Processing 342 of 500 batches (2 sequences)\n",
      "Processing 343 of 500 batches (2 sequences)\n",
      "Processing 344 of 500 batches (2 sequences)\n",
      "Processing 345 of 500 batches (2 sequences)\n",
      "Processing 346 of 500 batches (2 sequences)\n",
      "Processing 347 of 500 batches (2 sequences)\n",
      "Processing 348 of 500 batches (2 sequences)\n",
      "Processing 349 of 500 batches (2 sequences)\n",
      "Processing 350 of 500 batches (2 sequences)\n",
      "Processing 351 of 500 batches (2 sequences)\n",
      "Processing 352 of 500 batches (2 sequences)\n",
      "Processing 353 of 500 batches (2 sequences)\n",
      "Processing 354 of 500 batches (2 sequences)\n",
      "Processing 355 of 500 batches (2 sequences)\n",
      "Processing 356 of 500 batches (2 sequences)\n",
      "Processing 357 of 500 batches (2 sequences)\n",
      "Processing 358 of 500 batches (2 sequences)\n",
      "Processing 359 of 500 batches (2 sequences)\n",
      "Processing 360 of 500 batches (2 sequences)\n",
      "Processing 361 of 500 batches (2 sequences)\n",
      "Processing 362 of 500 batches (2 sequences)\n",
      "Processing 363 of 500 batches (2 sequences)\n",
      "Processing 364 of 500 batches (2 sequences)\n",
      "Processing 365 of 500 batches (2 sequences)\n",
      "Processing 366 of 500 batches (2 sequences)\n",
      "Processing 367 of 500 batches (2 sequences)\n",
      "Processing 368 of 500 batches (2 sequences)\n",
      "Processing 369 of 500 batches (2 sequences)\n",
      "Processing 370 of 500 batches (2 sequences)\n",
      "Processing 371 of 500 batches (2 sequences)\n",
      "Processing 372 of 500 batches (2 sequences)\n",
      "Processing 373 of 500 batches (2 sequences)\n",
      "Processing 374 of 500 batches (2 sequences)\n",
      "Processing 375 of 500 batches (2 sequences)\n",
      "Processing 376 of 500 batches (2 sequences)\n",
      "Processing 377 of 500 batches (2 sequences)\n",
      "Processing 378 of 500 batches (2 sequences)\n",
      "Processing 379 of 500 batches (2 sequences)\n",
      "Processing 380 of 500 batches (2 sequences)\n",
      "Processing 381 of 500 batches (2 sequences)\n",
      "Processing 382 of 500 batches (2 sequences)\n",
      "Processing 383 of 500 batches (2 sequences)\n",
      "Processing 384 of 500 batches (2 sequences)\n",
      "Processing 385 of 500 batches (2 sequences)\n",
      "Processing 386 of 500 batches (2 sequences)\n",
      "Processing 387 of 500 batches (2 sequences)\n",
      "Processing 388 of 500 batches (2 sequences)\n",
      "Processing 389 of 500 batches (2 sequences)\n",
      "Processing 390 of 500 batches (2 sequences)\n",
      "Processing 391 of 500 batches (2 sequences)\n",
      "Processing 392 of 500 batches (2 sequences)\n",
      "Processing 393 of 500 batches (2 sequences)\n",
      "Processing 394 of 500 batches (2 sequences)\n",
      "Processing 395 of 500 batches (2 sequences)\n",
      "Processing 396 of 500 batches (2 sequences)\n",
      "Processing 397 of 500 batches (2 sequences)\n",
      "Processing 398 of 500 batches (2 sequences)\n",
      "Processing 399 of 500 batches (2 sequences)\n",
      "Processing 400 of 500 batches (2 sequences)\n",
      "Processing 401 of 500 batches (2 sequences)\n",
      "Processing 402 of 500 batches (2 sequences)\n",
      "Processing 403 of 500 batches (2 sequences)\n",
      "Processing 404 of 500 batches (2 sequences)\n",
      "Processing 405 of 500 batches (2 sequences)\n",
      "Processing 406 of 500 batches (2 sequences)\n",
      "Processing 407 of 500 batches (2 sequences)\n",
      "Processing 408 of 500 batches (2 sequences)\n",
      "Processing 409 of 500 batches (2 sequences)\n",
      "Processing 410 of 500 batches (2 sequences)\n",
      "Processing 411 of 500 batches (2 sequences)\n",
      "Processing 412 of 500 batches (2 sequences)\n",
      "Processing 413 of 500 batches (2 sequences)\n",
      "Processing 414 of 500 batches (2 sequences)\n",
      "Processing 415 of 500 batches (2 sequences)\n",
      "Processing 416 of 500 batches (2 sequences)\n",
      "Processing 417 of 500 batches (2 sequences)\n",
      "Processing 418 of 500 batches (2 sequences)\n",
      "Processing 419 of 500 batches (2 sequences)\n",
      "Processing 420 of 500 batches (2 sequences)\n",
      "Processing 421 of 500 batches (2 sequences)\n",
      "Processing 422 of 500 batches (2 sequences)\n",
      "Processing 423 of 500 batches (2 sequences)\n",
      "Processing 424 of 500 batches (2 sequences)\n",
      "Processing 425 of 500 batches (2 sequences)\n",
      "Processing 426 of 500 batches (2 sequences)\n",
      "Processing 427 of 500 batches (2 sequences)\n",
      "Processing 428 of 500 batches (2 sequences)\n",
      "Processing 429 of 500 batches (2 sequences)\n",
      "Processing 430 of 500 batches (2 sequences)\n",
      "Processing 431 of 500 batches (2 sequences)\n",
      "Processing 432 of 500 batches (2 sequences)\n",
      "Processing 433 of 500 batches (2 sequences)\n",
      "Processing 434 of 500 batches (2 sequences)\n",
      "Processing 435 of 500 batches (2 sequences)\n",
      "Processing 436 of 500 batches (2 sequences)\n",
      "Processing 437 of 500 batches (2 sequences)\n",
      "Processing 438 of 500 batches (2 sequences)\n",
      "Processing 439 of 500 batches (2 sequences)\n",
      "Processing 440 of 500 batches (2 sequences)\n",
      "Processing 441 of 500 batches (2 sequences)\n",
      "Processing 442 of 500 batches (2 sequences)\n",
      "Processing 443 of 500 batches (2 sequences)\n",
      "Processing 444 of 500 batches (2 sequences)\n",
      "Processing 445 of 500 batches (2 sequences)\n",
      "Processing 446 of 500 batches (2 sequences)\n",
      "Processing 447 of 500 batches (2 sequences)\n",
      "Processing 448 of 500 batches (2 sequences)\n",
      "Processing 449 of 500 batches (2 sequences)\n",
      "Processing 450 of 500 batches (2 sequences)\n",
      "Processing 451 of 500 batches (2 sequences)\n",
      "Processing 452 of 500 batches (2 sequences)\n",
      "Processing 453 of 500 batches (2 sequences)\n",
      "Processing 454 of 500 batches (2 sequences)\n",
      "Processing 455 of 500 batches (2 sequences)\n",
      "Processing 456 of 500 batches (2 sequences)\n",
      "Processing 457 of 500 batches (2 sequences)\n",
      "Processing 458 of 500 batches (2 sequences)\n",
      "Processing 459 of 500 batches (2 sequences)\n",
      "Processing 460 of 500 batches (2 sequences)\n",
      "Processing 461 of 500 batches (2 sequences)\n",
      "Processing 462 of 500 batches (2 sequences)\n",
      "Processing 463 of 500 batches (2 sequences)\n",
      "Processing 464 of 500 batches (2 sequences)\n",
      "Processing 465 of 500 batches (2 sequences)\n",
      "Processing 466 of 500 batches (2 sequences)\n",
      "Processing 467 of 500 batches (2 sequences)\n",
      "Processing 468 of 500 batches (2 sequences)\n",
      "Processing 469 of 500 batches (2 sequences)\n",
      "Processing 470 of 500 batches (2 sequences)\n",
      "Processing 471 of 500 batches (2 sequences)\n",
      "Processing 472 of 500 batches (2 sequences)\n",
      "Processing 473 of 500 batches (2 sequences)\n",
      "Processing 474 of 500 batches (2 sequences)\n",
      "Processing 475 of 500 batches (2 sequences)\n",
      "Processing 476 of 500 batches (2 sequences)\n",
      "Processing 477 of 500 batches (2 sequences)\n",
      "Processing 478 of 500 batches (2 sequences)\n",
      "Processing 479 of 500 batches (2 sequences)\n",
      "Processing 480 of 500 batches (2 sequences)\n",
      "Processing 481 of 500 batches (2 sequences)\n",
      "Processing 482 of 500 batches (2 sequences)\n",
      "Processing 483 of 500 batches (2 sequences)\n",
      "Processing 484 of 500 batches (2 sequences)\n",
      "Processing 485 of 500 batches (2 sequences)\n",
      "Processing 486 of 500 batches (2 sequences)\n",
      "Processing 487 of 500 batches (2 sequences)\n",
      "Processing 488 of 500 batches (2 sequences)\n",
      "Processing 489 of 500 batches (2 sequences)\n",
      "Processing 490 of 500 batches (2 sequences)\n",
      "Processing 491 of 500 batches (2 sequences)\n",
      "Processing 492 of 500 batches (2 sequences)\n",
      "Processing 493 of 500 batches (2 sequences)\n",
      "Processing 494 of 500 batches (2 sequences)\n",
      "Processing 495 of 500 batches (2 sequences)\n",
      "Processing 496 of 500 batches (2 sequences)\n",
      "Processing 497 of 500 batches (2 sequences)\n",
      "Processing 498 of 500 batches (2 sequences)\n",
      "Processing 499 of 500 batches (2 sequences)\n",
      "Processing 500 of 500 batches (2 sequences)\n"
     ]
    }
   ],
   "source": [
    "# Generate embeddings using ESM-2 model\n",
    "print(f\"Generating embeddings for {len(new_seqs)} sequences...\")\n",
    "print(\"This may take several minutes depending on the number of sequences.\")\n",
    "\n",
    "! python mount/src/embeddings.py --fasta {FASTA_PATH} --output_dir {EMBEDDINGS_DIR} --truncation_seq_length 238"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prediction-header",
   "metadata": {},
   "source": [
    "# Predict Activity for New Sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "load-embeddings",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 1000 embedding files from mount/outputs/new_seq_embeddings...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:06<00:00, 147.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded embeddings for 1000 sequences\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Process all sequence embeddings and generate predictions\n",
    "\n",
    "# Load embeddings from the generated files\n",
    "embedding_files = list(EMBEDDINGS_DIR.glob(\"*.pt\"))\n",
    "\n",
    "labels = []\n",
    "embeddings = []\n",
    "sequences = []\n",
    "\n",
    "print(f\"Processing {len(embedding_files)} embedding files from {EMBEDDINGS_DIR}...\")\n",
    "\n",
    "# Extract labels and embeddings from all files\n",
    "for emb_file in tqdm(embedding_files):\n",
    "    data = torch.load(emb_file)\n",
    "    label = data[\"label\"]\n",
    "    embedding = data[\"mean_representations\"][47]  # Use layer 47 (final transformer layer)\n",
    "    \n",
    "    # Convert label to actual sequence (WT + mutations)\n",
    "    seq = list(wt_seq)\n",
    "    for mutation in label.split(\":\"):\n",
    "        pos = int(mutation[:-1])\n",
    "        new_aa = mutation[-1]\n",
    "        seq[pos] = new_aa\n",
    "    sequence = \"\".join(seq)\n",
    "    \n",
    "    labels.append(label)\n",
    "    embeddings.append(embedding)\n",
    "    sequences.append(sequence)\n",
    "\n",
    "print(f\"Loaded embeddings for {len(embeddings)} sequences\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "generate-predictions",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated predictions for 1000 sequences\n",
      "Score range: 1.193 to 3.886\n"
     ]
    }
   ],
   "source": [
    "# Convert embeddings to tensor\n",
    "embeddings_tensor = torch.from_numpy(np.array(embeddings)).float().to(device)\n",
    "\n",
    "# Generate predictions\n",
    "with torch.no_grad():\n",
    "    predictions = model(embeddings_tensor).cpu().flatten().detach().numpy()\n",
    "\n",
    "print(f\"Generated predictions for {len(predictions)} sequences\")\n",
    "print(f\"Score range: {predictions.min():.3f} to {predictions.max():.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ranking-header",
   "metadata": {},
   "source": [
    "# Rank and Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "create-results",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created ranked results for 1000 sequences\n",
      "\n",
      "Top 5 sequences:\n",
      "   rank               label  predicted_score\n",
      "0     1  156Y:63I:195L:128Y         3.885675\n",
      "1     2   233E:189A:11A:12R         3.797362\n",
      "2     3  116Y:46A:196T:143F         3.790655\n",
      "3     4      86M:83Y:6V:28L         3.785476\n",
      "4     5  219M:104Q:51Q:157A         3.778043\n"
     ]
    }
   ],
   "source": [
    "results_df = pd.DataFrame({\n",
    "    \"label\": labels,\n",
    "    \"sequence\": sequences,\n",
    "    \"predicted_score\": predictions\n",
    "})\n",
    "\n",
    "# Sort by predicted score (highest first)\n",
    "results_df = results_df.sort_values(\"predicted_score\", ascending=False).reset_index(drop=True)\n",
    "results_df['rank'] = range(1, len(results_df) + 1)\n",
    "\n",
    "print(f\"Created ranked results for {len(results_df)} sequences\")\n",
    "print(f\"\\nTop 5 sequences:\")\n",
    "print(results_df[['rank', 'label', 'predicted_score']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "save-results",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to: mount/outputs/all_sequences_predictions.csv\n",
      "Results also saved as PyTorch object to: mount/outputs/all_sequences_predictions.pt\n",
      "\n",
      "=== Prediction Summary ===\n",
      "Total sequences predicted: 1000\n",
      "Score range: 1.193 to 3.886\n",
      "Mean predicted score: 1.852\n",
      "Std predicted score: 0.662\n"
     ]
    }
   ],
   "source": [
    "results_df.to_csv(RESULTS_CSV_PATH, index=False)\n",
    "print(f\"Results saved to: {RESULTS_CSV_PATH}\")\n",
    "\n",
    "# Save PyTorch tensor for compatibility\n",
    "torch.save(results_df, RESULTS_PT_PATH)\n",
    "print(f\"Results also saved as PyTorch object to: {RESULTS_PT_PATH}\")\n",
    "\n",
    "# Summary statistics\n",
    "print(f\"\\n=== Prediction Summary ===\")\n",
    "print(f\"Total sequences predicted: {len(results_df)}\")\n",
    "print(f\"Score range: {results_df['predicted_score'].min():.3f} to {results_df['predicted_score'].max():.3f}\")\n",
    "print(f\"Mean predicted score: {results_df['predicted_score'].mean():.3f}\")\n",
    "print(f\"Std predicted score: {results_df['predicted_score'].std():.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "save-top-sequences",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 sequences saved to: mount/outputs/top_5_sequences.fasta\n",
      "Bottom 5 sequences saved to: mount/outputs/bottom_5_sequences.fasta\n"
     ]
    }
   ],
   "source": [
    "# Save top 5 sequences\n",
    "with open(TOP_5_FASTA_PATH, \"w\") as fh:\n",
    "    for _, row in results_df.head(5).iterrows():\n",
    "        fh.write(f\">{row['label']}|score:{row['predicted_score']:.3f}|rank:{row['rank']}\\n\")\n",
    "        fh.write(f\"{row['sequence']}\\n\")\n",
    "print(f\"Top 5 sequences saved to: {TOP_5_FASTA_PATH}\")\n",
    "\n",
    "# Save bottom 5 sequences for comparison\n",
    "with open(BOTTOM_5_FASTA_PATH, \"w\") as fh:\n",
    "    for _, row in results_df.tail(5).iterrows():\n",
    "        fh.write(f\">{row['label']}|score:{row['predicted_score']:.3f}|rank:{row['rank']}\\n\")\n",
    "        fh.write(f\"{row['sequence']}\\n\")\n",
    "print(f\"Bottom 5 sequences saved to: {BOTTOM_5_FASTA_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "completion-header",
   "metadata": {},
   "source": [
    "# Sequence Generation Complete\n",
    "\n",
    "Successfully generated, filtered, and ranked protein sequences by predicted activity. The results are saved and ready for visualization in the figures notebook (`03_create_figures.ipynb`).\n",
    "\n",
    "## Files Created:\n",
    "- `outputs/all_sequences_predictions.csv` - Full ranked results\n",
    "- `outputs/top_5_sequences.fasta` - Top 5 predicted sequences\n",
    "- `outputs/bottom_5_sequences.fasta` - Bottom 5 predicted sequences"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
