{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experimental data analysis and figure generation\n",
    "\n",
    "This notebook analyzes experimental data obtained from expressing our select GFPs in *E. coli* and measuring their fluorescence using the SpectraMax iD3 plate reader. The notebook also creates figures for the pub."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import arcadia_pycolor as apc\n",
    "\n",
    "# Set style for publication-quality figures\n",
    "apc.mpl.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define data paths\n",
    "OUTPUTS_DIR = Path(\"../experimental_data/\")\n",
    "FIGURES_DIR = Path(\"../figures/\")\n",
    "FIGURES_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "# Figure output paths\n",
    "FIG1_PATH = FIGURES_DIR / 'training_data.svg'\n",
    "FIG2_PATH = FIGURES_DIR / 'experimental_data.svg'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = pd.read_csv(\"../data/seq_and_score.csv\")\n",
    "experimental_data_rep1_rep2 = pd.read_csv(\"../experimental_data/032125_rep1_rep2.csv\", header=None)\n",
    "experimental_data_rep3 = pd.read_csv(\"../experimental_data/042425_rep3.csv\", header=None)\n",
    "experimental_data_rep4 = pd.read_csv(\"../experimental_data/043025_rep4.csv\", header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 1: Comparison to training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize all data to wild-type for comparison\n",
    "def add_wt_normalized_column(df):\n",
    "    ref_score = df.loc[df['id'] == 'avgfp_00000', 'score']\n",
    "    \n",
    "    df['wt_normalized'] = df['score'] / ref_score.values[0]\n",
    "    return df\n",
    "\n",
    "normalized_sarkisyan_data = add_wt_normalized_column(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_data = normalized_sarkisyan_data.sort_values(by=\"wt_normalized\", ascending=False).reset_index(drop=True)\n",
    "\n",
    "# Bin the data to make graph size manageable\n",
    "bin_size = 100\n",
    "n_bins = len(sorted_data) // bin_size\n",
    "binned_values = (\n",
    "    sorted_data[\"wt_normalized\"]\n",
    "    .values[:n_bins * bin_size]\n",
    "    .reshape(n_bins, bin_size)\n",
    "    .mean(axis=1)\n",
    ")\n",
    "\n",
    "# Graph values\n",
    "x = np.arange(len(binned_values))\n",
    "fig, ax = plt.subplots(figsize=apc.mpl.get_figure_dimensions(\"float_square\"))\n",
    "bars = ax.bar(x, binned_values, zorder=1, width=1.0)\n",
    "\n",
    "# Add gradient colors\n",
    "cmap = apc.gradients.greens.to_mpl_cmap()\n",
    "n = len(bars)\n",
    "for i, bar in enumerate(bars):\n",
    "    u = i / (n - 1)\n",
    "    t = min(1.0, max(0.0, 0.5 + 0.5 * u**0.4)) # 0.4 for contrast\n",
    "    bar.set_facecolor(cmap(t))\n",
    "\n",
    "# Mark best, mid, worst values\n",
    "targets = {\"Best\": 1.108, \"Mid\": 0.810, \"Worst\": 0.345}\n",
    "for label, val in targets.items(): \n",
    "    idx = np.abs(binned_values - val).argmin()\n",
    "    ax.axvline(x=idx, zorder=10, color=apc.black)\n",
    "    ax.text(idx + 5, ax.get_ylim()[1] * 1, label, zorder=11)\n",
    "\n",
    "apc.mpl.style_plot(ax, monospaced_axes=\"y\")\n",
    "plt.ylabel(\"Wild-type normalized score\")\n",
    "plt.xlabel(\"Sample\")\n",
    "ax.set_xticks([])\n",
    "plt.show()\n",
    "fig.savefig(FIG1_PATH, format=\"svg\", bbox_inches=\"tight\", dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 2: Experimental data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parse plate reader data\n",
    "We used a SpectraMax iD3 plate reader for our fluorescence intensity measures. We created a single file for each analysis and added a new plate for each measurement, naming the plate which day of the experiment we were on (day1, day2, etc.). We downloaded the raw XML file from the plate reader and turned it into a CSV file, which we parse here. Additionally, we're extracting day 2 data from our maturation data to use for our analysis as both the green and red fluorescence are reasonably bright and the cells are still healthy. We have four replicates of this data that can be found in the `experimental_data` directory.\n",
    "\n",
    "The final output of this section is a dataframe (that's also saved as a CSV in the `experimental_data`) with the following columns: \n",
    "- sample: the sample name\n",
    "- value_485_525: the fluorescence intensity at 485/525 (green) on day 2\n",
    "- value_560_670: the fluorescence intensity at 560/670 (red) on day 2\n",
    "- rep: the replicate number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_day2_data(df, well_map):\n",
    "    plate_indices = df[df[0] == \"Plate name\"].index\n",
    "    for idx in plate_indices:\n",
    "        if str(df.iloc[idx, 1]).strip().lower() == \"day2\":\n",
    "            day2_idx = idx\n",
    "            break\n",
    "    else:\n",
    "        raise ValueError(\"No 'day2' plate found in file.\")\n",
    "\n",
    "    wl1_start = day2_idx + 42\n",
    "    wl2_start = day2_idx + 52\n",
    "\n",
    "    rows = list(\"ABCDEFGH\")\n",
    "    cols = list(range(1, 13))\n",
    "\n",
    "    def extract_block(start_row):\n",
    "        block = df.iloc[start_row:start_row + 8, 2:14].copy()\n",
    "        block.index = rows\n",
    "        block.columns = cols\n",
    "        return block\n",
    "\n",
    "    def melt_block(block, label):\n",
    "        melted = block.stack().reset_index()\n",
    "        melted.columns = [\"row\", \"column\", label]\n",
    "        melted[\"well\"] = melted[\"row\"] + melted[\"column\"].astype(str)\n",
    "        return melted[[\"well\", label]]\n",
    "\n",
    "    block_485 = extract_block(wl1_start)\n",
    "    block_670 = extract_block(wl2_start)\n",
    "\n",
    "    melted_485 = melt_block(block_485, \"value_485_525\")\n",
    "    melted_670 = melt_block(block_670, \"value_560_670\")\n",
    "\n",
    "    merged = pd.merge(melted_485, melted_670, on=\"well\")\n",
    "    merged[\"sample\"] = merged[\"well\"].map(well_map)\n",
    "    merged = merged.dropna(subset=[\"sample\"])\n",
    "\n",
    "    return merged[[\"sample\", \"value_485_525\", \"value_560_670\"]]\n",
    "\n",
    "well_map = {\n",
    "    \"A1\": \"GFP1_1\", \n",
    "    \"A2\": \"GFP1_2\", \n",
    "    \"A3\": \"GFP1_3\",\n",
    "    \"A4\": \"GFP1_4\", \n",
    "    \"A5\": \"GFP1_5\",\n",
    "    \"A6\": \"GFP1_6\",\n",
    "    \"A7\": \"GFP1_7\",\n",
    "    \"A8\": \"GFP1_8\",\n",
    "    \"A9\": \"GFP1_9\",\n",
    "    \"A10\": \"GFP1_10\",\n",
    "    \"B1\": \"Wild-type\",\n",
    "    \"B2\": \"Best\", \n",
    "    \"B3\": \"Mid\", \n",
    "    \"B4\": \"Worst\",\n",
    "    \"B6\": \"Empty_vector\"\n",
    "}\n",
    "\n",
    "well_map_rep2 = {\n",
    "    \"C1\": \"GFP1_1\", \n",
    "    \"C2\": \"GFP1_2\", \n",
    "    \"C3\": \"GFP1_3\",\n",
    "    \"C4\": \"GFP1_4\", \n",
    "    \"C5\": \"GFP1_5\",\n",
    "    \"C6\": \"GFP1_6\",\n",
    "    \"C7\": \"GFP1_7\",\n",
    "    \"C8\": \"GFP1_8\",\n",
    "    \"C9\": \"GFP1_9\",\n",
    "    \"C10\": \"GFP1_10\",\n",
    "    \"D1\": \"Wild-type\",\n",
    "    \"D2\": \"Best\", \n",
    "    \"D3\": \"Mid\", \n",
    "    \"D4\": \"Worst\", \n",
    "    \"D6\": \"Empty_vector\"\n",
    "}\n",
    "\n",
    "exp_data_rep1 = extract_day2_data(experimental_data_rep1_rep2, well_map)\n",
    "exp_data_rep2 = extract_day2_data(experimental_data_rep1_rep2, well_map_rep2)\n",
    "exp_data_rep3 = extract_day2_data(experimental_data_rep3, well_map)\n",
    "exp_data_rep4 = extract_day2_data(experimental_data_rep4, well_map)\n",
    "\n",
    "exp_data_rep1[\"rep\"] = 1\n",
    "exp_data_rep2[\"rep\"] = 2\n",
    "exp_data_rep3[\"rep\"] = 3\n",
    "exp_data_rep4[\"rep\"] = 4\n",
    "\n",
    "compiled_experimental_data = pd.concat(\n",
    "    [exp_data_rep1, exp_data_rep2, exp_data_rep3, exp_data_rep4],\n",
    "    ignore_index=True\n",
    ")\n",
    "\n",
    "compiled_experimental_data.to_csv(\"../experimental_data/compiled_experimental_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Background subtraction and normalization\n",
    "In addition to measuring the fluorescence values for our samples of interest, we also measured the values for cells containing an empty vector with no fluorescent protein to use as a background control. Here, we subtract the green and red fluorescent values for the empty_vector from the corresponding values for the sample. \n",
    "\n",
    "Additionally, we created a fusion protein where RFP serves as an expression control for our GFP. Therefore, we normalize our GFP fluorescence, by dividing by the RFP fluorescence. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subtract background\n",
    "def subtract_background(df: pd.DataFrame, empty_label: str = \"Empty_vector\", suffix: str = \"_bkgd_sub\",) -> pd.DataFrame:\n",
    "    CHANNELS = [\"value_485_525\", \"value_560_670\"]\n",
    "    df_out = df.copy()\n",
    "    empty = df_out[df_out[\"sample\"] == empty_label]\n",
    "    keys = [\"rep\"]\n",
    "    bg = empty.set_index(keys)[CHANNELS]\n",
    "    merged = df_out.merge(bg, left_on=keys, right_index=True, how=\"left\", suffixes=(\"\", \"_bkgd\"))\n",
    "    for col in CHANNELS:\n",
    "        merged[f\"{col}{suffix}\"] = merged[col] - merged[f\"{col}_bkgd\"]\n",
    "    return merged\n",
    "\n",
    "# Normalize GFP data using RFP data\n",
    "def compute_green_red_ratio(df):\n",
    "    df = df.copy()\n",
    "    df['Green/Red'] = df['value_485_525_bkgd_sub'] / df['value_560_670_bkgd_sub']\n",
    "    return df\n",
    "\n",
    "experimental_data_day_2_bkgd_subtract = subtract_background(compiled_experimental_data)\n",
    "normalized_experimental_data = compute_green_red_ratio(experimental_data_day_2_bkgd_subtract)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalizing to wild-type\n",
    "In order to qualitatively compare our data to the data from Sarkisyan et al., we normalized to the wild-type GFP/RFP ratio. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_to_wt(df, wt_label=\"Wild-type\", value_col=\"Green/Red\", suffix=\"_wt_normalized\"):\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Filter WT values for each replicate\n",
    "    wt_values = df[df[\"sample\"] == wt_label][[\"rep\", value_col]].rename(columns={value_col: \"wt_value\"})\n",
    "\n",
    "    # Merge WT values back onto all rows by replicate\n",
    "    df = df.merge(wt_values, on=\"rep\", how=\"left\")\n",
    "\n",
    "    # Normalize\n",
    "    df[f\"{value_col}{suffix}\"] = df[value_col] / df[\"wt_value\"]\n",
    "\n",
    "    return df\n",
    "\n",
    "def summarize_replicates(df):\n",
    "    summary = (\n",
    "        df.groupby([\"sample\"])\n",
    "          .agg({\n",
    "              \"Green/Red_wt_normalized\": [\"mean\", \"std\"]\n",
    "          })\n",
    "    )\n",
    "    summary.columns = [\"_\".join(col).strip() for col in summary.columns.values]\n",
    "    summary = summary.reset_index()\n",
    "    return summary\n",
    "\n",
    "\n",
    "normalized_to_wt_exp_data = normalize_to_wt(normalized_experimental_data)\n",
    "averaged_wt_normalized_data = summarize_replicates(normalized_to_wt_exp_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graphing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graph normalized data\n",
    "sorted_data = averaged_wt_normalized_data.sort_values(by='Green/Red_wt_normalized_mean', ascending=False).reset_index(drop=True)\n",
    "\n",
    "# Create bar plot\n",
    "fig, ax = plt.subplots(figsize=apc.mpl.get_figure_dimensions(\"half_square\"), layout=\"constrained\")\n",
    "bars = plt.bar(\n",
    "    sorted_data[\"sample\"],\n",
    "    sorted_data[\"Green/Red_wt_normalized_mean\"],\n",
    "    edgecolor=apc.black,\n",
    "    linewidth=0.5,\n",
    "    zorder=1,\n",
    ")\n",
    "\n",
    "# Add gradient colors\n",
    "cmap = apc.gradients.greens.to_mpl_cmap()\n",
    "n = len(bars)\n",
    "for i, bar in enumerate(bars):\n",
    "    u = i / (n - 1) if n > 1 else 0.5\n",
    "    t = min(1.0, max(0.0, 0.5 + 0.5 * u**0.4))  # contrast = 0.4\n",
    "    bar.set_facecolor(cmap(t))\n",
    "\n",
    "# Re-color controls\n",
    "override_colors = {\n",
    "    \"Wild-type\": apc.mud,\n",
    "    \"Best\": apc.mud,\n",
    "    \"Mid\": apc.mud,\n",
    "    \"Worst\": apc.mud,\n",
    "    \"Empty_vector\": apc.mud,\n",
    "}\n",
    "for bar, name in zip(bars, sorted_data[\"sample\"]):\n",
    "    if name in override_colors:\n",
    "        bar.set_facecolor(override_colors[name])\n",
    "\n",
    "# Add scatter plot\n",
    "rep_offset = {1: -0.1, 2: -0.07, 3: 0.07, 4: 0.1} \n",
    "for i, name in enumerate(sorted_data[\"sample\"]):\n",
    "    grp = normalized_to_wt_exp_data.loc[\n",
    "        normalized_to_wt_exp_data[\"sample\"] == name, [\"Green/Red_wt_normalized\", \"rep\"]\n",
    "    ].dropna()\n",
    "\n",
    "    if grp.empty:\n",
    "        continue\n",
    "\n",
    "    ys = grp[\"Green/Red_wt_normalized\"].to_numpy(dtype=float)\n",
    "    reps = grp[\"rep\"].to_numpy()\n",
    "    m = np.isfinite(ys)\n",
    "    ys, reps = ys[m], reps[m]\n",
    "    if ys.size == 0:\n",
    "        continue\n",
    "\n",
    "    xs = i + np.array([rep_offset.get(int(r), 0.0) for r in reps])\n",
    "    ax.scatter(xs, ys, s=28, facecolor=apc.black, zorder=3)\n",
    "\n",
    "apc.mpl.style_plot(ax, monospaced_axes=\"y\")\n",
    "plt.ylabel(\"GFP/RFP ratio (AU)\")\n",
    "plt.xlabel(\"Sample\")\n",
    "plt.xticks(rotation=45, ha=\"right\")\n",
    "plt.show()\n",
    "fig.savefig(FIG2_PATH, format=\"svg\", bbox_inches=\"tight\", dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.12.1 ('gfp_project')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0cbaa03cfba7adabb46ff87d6fd3947450f92ba1ae0214ae074ea92996ddf051"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
